# GPT-2 Implementation in C++

This repository contains an implementation of the GPT-2 language model in C++. The project aims to provide a basic understanding of how large language models work by implementing the core components of GPT-2. Additionally, the implementation includes some basic optimizations to improve performance.

## Features

- **Basic GPT-2 Implementation**: The core components of the GPT-2 model, including the transformer architecture, are implemented in C++.
- **Optimizations**: Several optimizations are included to improve the performance of the model, such as efficient matrix operations and memory management.
- **Modular Design**: The code is designed to be modular, making it easy to understand and extend.

## Getting Started

### Prerequisites

- C++ compiler (e.g., g++)
- Eigen library
- CMake (optional, for building the project)

### Building the Project

To build the project, you can use the provided Makefile or CMakeLists.txt file. Run the following command to build the project using the Makefile:

